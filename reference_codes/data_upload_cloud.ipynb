{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datalab.context import Context\r\n",
    "import google.datalab.storage as storage\r\n",
    "import google.datalab.bigquery as bq\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "from google.cloud import bigquery"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"auth/dados-publicos-326316-e16540376290.json\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # Imports the Google Cloud client library\r\n",
    "# from google.cloud import storage\r\n",
    "\r\n",
    "# # Instantiates a client\r\n",
    "# storage_client = storage.Client()\r\n",
    "\r\n",
    "# # The name for the new bucket\r\n",
    "# bucket_name = \"dna_public_teste\"\r\n",
    "\r\n",
    "# # Creates the new bucket\r\n",
    "# bucket = storage_client.create_bucket(bucket_name)\r\n",
    "\r\n",
    "# print(\"Bucket {} created.\".format(bucket.name))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bucket dna_public_teste created.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "client = bigquery.Client()\r\n",
    "dataset_id = f\"{client.project}.dna_dataset\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criar um dataset novo no projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Construct a BigQuery client object.\r\n",
    "client = bigquery.Client()\r\n",
    "\r\n",
    "# TODO(developer): Set dataset_id to the ID of the dataset to create.\r\n",
    "dataset_id = f\"{client.project}.dna_dataset\"\r\n",
    "\r\n",
    "# Construct a full Dataset object to send to the API.\r\n",
    "dataset = bigquery.Dataset(dataset_id)\r\n",
    "\r\n",
    "# TODO(developer): Specify the geographic location where the dataset should reside.\r\n",
    "dataset.location = \"US\"\r\n",
    "\r\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\r\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\r\n",
    "# exists within the project.\r\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\r\n",
    "print(f\"Created dataset {client.project}.{dataset.dataset_id}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created dataset dados-publicos-326316.dna_dataset\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Criando tabelas com os schemas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Set table_id to the ID of the table to create.\r\n",
    "table_id = f\"{dataset_id}.simples_format\"\r\n",
    "\r\n",
    "schema = [\r\n",
    "    bigquery.SchemaField(\"cnpj\", \"STRING\", mode=\"REQUIRED\"),\r\n",
    "    bigquery.SchemaField(\"opcao_simples\", \"STRING\"),\r\n",
    "    bigquery.SchemaField(\"data_opcao_simples\", \"DATE\", mode=\"NULLABLE\"),\r\n",
    "    bigquery.SchemaField(\"data_exclusao_simples\", \"DATE\", mode=\"NULLABLE\"),\r\n",
    "    bigquery.SchemaField(\"opcao_mei\", \"STRING\"),\r\n",
    "    bigquery.SchemaField(\"data_opcao_mei\", \"DATE\", mode=\"NULLABLE\"),\r\n",
    "    bigquery.SchemaField(\"data_exclusao_mei\", \"DATE\", mode=\"NULLABLE\"),\r\n",
    "]\r\n",
    "\r\n",
    "table = bigquery.Table(table_id, schema=schema)\r\n",
    "table = client.create_table(table)  # Make an API request.\r\n",
    "print(\r\n",
    "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created table dados-publicos-326316.dna_dataset.simples_format\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando do GCS para o BigQuery"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Construct a BigQuery client object.\r\n",
    "client = bigquery.Client()\r\n",
    "\r\n",
    "directory = 'empresas'\r\n",
    "dataset_id= f\"{client.project}.dna_test_dataset\"\r\n",
    "\r\n",
    "# Set table_id to the ID of the table to create.\r\n",
    "table_id = f\"{dataset_id}.empresas_teste\"\r\n",
    "\r\n",
    "job_config = bigquery.LoadJobConfig(source_format=bigquery.SourceFormat.PARQUET,)\r\n",
    "uri = f\"gs://dna_public_cnpj_files/empresas_trusted_parquet/*.parquet\"\r\n",
    "\r\n",
    "load_job = client.load_table_from_uri(\r\n",
    "    uri, table_id, job_config=job_config\r\n",
    ")  # Make an API request.\r\n",
    "\r\n",
    "load_job.result()  # Waits for the job to complete.\r\n",
    "\r\n",
    "destination_table = client.get_table(table_id)\r\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 46906616 rows.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "d1678312ba1ea9aec5d2fa5e059815f637844f0d2bb281feb437b6cf7d563b2b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}